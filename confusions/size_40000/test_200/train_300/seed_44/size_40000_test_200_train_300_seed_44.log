Device: cuda

=== Hyperparameters ===
input_features: 21
num_coords: 3
max_frames: 400
batch_size: 64
epochs: 100
lr: 0.0005
weight_decay: 0.001
patience: 6
lr_scheduler_patience: 3
cooldown: 0
min_delta: 0.01
device: cuda
[DEBUG] Model and optimizer setup complete. About to start training loop.

=== Config: 300 train signs | 200 test signs | Seed: 44 | Size: 40000 ===

Normalization Stats done
Train Set done
Val Set done
Test Set done
Test Subset Set done
Train Loader done
Val Loader done
Test Loader done
Test Subset Loader done
[Seed 44] Train Set Size: 40000
[Seed 44] Val Set Size: 24403, Test Set Size: 22869
Applied He weight initialization
Total number of parameters: 2253300

=== Model Architecture ===
TransformerClassifier(
  (embedding): Linear(in_features=63, out_features=256, bias=True)
  (pos_encoder): PositionalEncoding(
    (dropout): Dropout(p=0.05, inplace=False)
  )
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-3): 4 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=512, bias=True)
        (dropout): Dropout(p=0.3, inplace=False)
        (linear2): Linear(in_features=512, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.3, inplace=False)
        (dropout2): Dropout(p=0.3, inplace=False)
      )
    )
  )
  (pooling): AdaptiveAvgPool1d(output_size=1)
  (final_dropout): Dropout(p=0.2, inplace=False)
  (fc_train): Linear(in_features=256, out_features=300, bias=True)
  (fc_test): Linear(in_features=256, out_features=200, bias=True)
)
/home/tdahake3/miniconda3/envs/fs_dl2/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
scheduler initialized
Epoch 00 | LR: 5.00e-04 | Train Loss: 5.8319% | Train Acc: 0.38% | Val Loss: 6.2875% | Val Acc: 0.57% | Val Acc (Test Head Only): 0.30%
Epoch 01 | LR: 5.00e-04 | Train Loss: 5.6677% | Train Acc: 0.55% | Val Loss: 5.6295% | Val Acc: 0.88% | Val Acc (Test Head Only): 1.43%
Epoch 02 | LR: 5.00e-04 | Train Loss: 5.0394% | Train Acc: 2.44% | Val Loss: 4.1868% | Val Acc: 7.77% | Val Acc (Test Head Only): 10.80%
Epoch 03 | LR: 5.00e-04 | Train Loss: 4.1030% | Train Acc: 9.83% | Val Loss: 3.2535% | Val Acc: 21.84% | Val Acc (Test Head Only): 26.76%
Epoch 04 | LR: 5.00e-04 | Train Loss: 3.4336% | Train Acc: 19.86% | Val Loss: 2.6748% | Val Acc: 32.16% | Val Acc (Test Head Only): 37.80%
Epoch 05 | LR: 5.00e-04 | Train Loss: 2.9323% | Train Acc: 28.68% | Val Loss: 2.2542% | Val Acc: 41.44% | Val Acc (Test Head Only): 48.42%
Epoch 06 | LR: 5.00e-04 | Train Loss: 2.5947% | Train Acc: 35.72% | Val Loss: 2.0152% | Val Acc: 47.10% | Val Acc (Test Head Only): 53.84%
Epoch 07 | LR: 5.00e-04 | Train Loss: 2.3385% | Train Acc: 41.07% | Val Loss: 1.6830% | Val Acc: 54.64% | Val Acc (Test Head Only): 61.11%
Epoch 08 | LR: 5.00e-04 | Train Loss: 2.1490% | Train Acc: 45.41% | Val Loss: 1.5907% | Val Acc: 56.89% | Val Acc (Test Head Only): 62.96%
Epoch 09 | LR: 5.00e-04 | Train Loss: 1.9927% | Train Acc: 48.73% | Val Loss: 1.4749% | Val Acc: 59.28% | Val Acc (Test Head Only): 65.92%
Epoch 10 | LR: 5.00e-04 | Train Loss: 1.8807% | Train Acc: 51.24% | Val Loss: 1.4175% | Val Acc: 60.07% | Val Acc (Test Head Only): 66.05%
Epoch 11 | LR: 5.00e-04 | Train Loss: 1.7930% | Train Acc: 53.22% | Val Loss: 1.2996% | Val Acc: 63.48% | Val Acc (Test Head Only): 69.64%
Epoch 12 | LR: 5.00e-04 | Train Loss: 1.7110% | Train Acc: 55.34% | Val Loss: 1.1690% | Val Acc: 66.55% | Val Acc (Test Head Only): 72.39%
Epoch 13 | LR: 5.00e-04 | Train Loss: 1.6417% | Train Acc: 57.08% | Val Loss: 1.1623% | Val Acc: 67.36% | Val Acc (Test Head Only): 72.90%
Epoch 14 | LR: 5.00e-04 | Train Loss: 1.5870% | Train Acc: 58.52% | Val Loss: 1.1754% | Val Acc: 67.02% | Val Acc (Test Head Only): 72.48%
Epoch 15 | LR: 5.00e-04 | Train Loss: 1.5311% | Train Acc: 59.27% | Val Loss: 1.1223% | Val Acc: 68.45% | Val Acc (Test Head Only): 73.64%
Epoch 16 | LR: 5.00e-04 | Train Loss: 1.5023% | Train Acc: 60.32% | Val Loss: 1.0863% | Val Acc: 68.79% | Val Acc (Test Head Only): 74.51%
Epoch 17 | LR: 5.00e-04 | Train Loss: 1.4510% | Train Acc: 61.46% | Val Loss: 1.0951% | Val Acc: 69.16% | Val Acc (Test Head Only): 75.53%
Epoch 18 | LR: 5.00e-04 | Train Loss: 1.4214% | Train Acc: 62.10% | Val Loss: 1.0473% | Val Acc: 69.61% | Val Acc (Test Head Only): 75.55%
Epoch 19 | LR: 5.00e-04 | Train Loss: 1.3893% | Train Acc: 62.63% | Val Loss: 1.0150% | Val Acc: 70.34% | Val Acc (Test Head Only): 76.10%
Epoch 20 | LR: 5.00e-04 | Train Loss: 1.3582% | Train Acc: 63.24% | Val Loss: 0.9484% | Val Acc: 72.56% | Val Acc (Test Head Only): 78.06%
Epoch 21 | LR: 5.00e-04 | Train Loss: 1.3377% | Train Acc: 64.16% | Val Loss: 1.0025% | Val Acc: 71.22% | Val Acc (Test Head Only): 76.86%
Epoch 22 | LR: 5.00e-04 | Train Loss: 1.3173% | Train Acc: 64.69% | Val Loss: 0.9640% | Val Acc: 72.05% | Val Acc (Test Head Only): 77.63%
Epoch 23 | LR: 5.00e-04 | Train Loss: 1.2888% | Train Acc: 65.06% | Val Loss: 0.9779% | Val Acc: 71.66% | Val Acc (Test Head Only): 76.43%
Epoch 24 | LR: 5.00e-04 | Train Loss: 1.2833% | Train Acc: 65.44% | Val Loss: 0.9187% | Val Acc: 73.54% | Val Acc (Test Head Only): 78.54%
Epoch 25 | LR: 5.00e-04 | Train Loss: 1.2755% | Train Acc: 65.82% | Val Loss: 0.8674% | Val Acc: 74.53% | Val Acc (Test Head Only): 80.01%
Epoch 26 | LR: 5.00e-04 | Train Loss: 1.2408% | Train Acc: 66.55% | Val Loss: 0.9296% | Val Acc: 73.06% | Val Acc (Test Head Only): 78.14%
Epoch 27 | LR: 5.00e-04 | Train Loss: 1.2411% | Train Acc: 66.30% | Val Loss: 0.9116% | Val Acc: 73.75% | Val Acc (Test Head Only): 79.31%
Epoch 28 | LR: 5.00e-04 | Train Loss: 1.2153% | Train Acc: 67.17% | Val Loss: 0.9049% | Val Acc: 73.30% | Val Acc (Test Head Only): 78.93%
Epoch 29 | LR: 5.00e-04 | Train Loss: 1.2101% | Train Acc: 67.26% | Val Loss: 0.8536% | Val Acc: 74.70% | Val Acc (Test Head Only): 80.30%
Epoch 30 | LR: 5.00e-04 | Train Loss: 1.1972% | Train Acc: 67.48% | Val Loss: 0.9001% | Val Acc: 73.74% | Val Acc (Test Head Only): 78.99%
Epoch 31 | LR: 5.00e-04 | Train Loss: 1.2030% | Train Acc: 67.58% | Val Loss: 0.8409% | Val Acc: 75.38% | Val Acc (Test Head Only): 79.92%
Epoch 32 | LR: 5.00e-04 | Train Loss: 1.1830% | Train Acc: 67.91% | Val Loss: 0.8712% | Val Acc: 74.88% | Val Acc (Test Head Only): 80.01%
Epoch 33 | LR: 5.00e-04 | Train Loss: 1.1766% | Train Acc: 68.01% | Val Loss: 0.9162% | Val Acc: 73.57% | Val Acc (Test Head Only): 78.90%
Epoch 34 | LR: 5.00e-04 | Train Loss: 1.1646% | Train Acc: 68.51% | Val Loss: 0.8811% | Val Acc: 74.53% | Val Acc (Test Head Only): 79.58%
Epoch 35 | LR: 2.50e-04 | Train Loss: 1.1465% | Train Acc: 68.83% | Val Loss: 0.8444% | Val Acc: 75.38% | Val Acc (Test Head Only): 81.04%
Epoch 36 | LR: 2.50e-04 | Train Loss: 0.9945% | Train Acc: 72.92% | Val Loss: 0.6983% | Val Acc: 79.26% | Val Acc (Test Head Only): 84.53%
Epoch 37 | LR: 2.50e-04 | Train Loss: 0.9564% | Train Acc: 74.16% | Val Loss: 0.7157% | Val Acc: 79.15% | Val Acc (Test Head Only): 84.04%
Epoch 38 | LR: 2.50e-04 | Train Loss: 0.9718% | Train Acc: 73.42% | Val Loss: 0.7037% | Val Acc: 79.32% | Val Acc (Test Head Only): 84.29%
Epoch 39 | LR: 2.50e-04 | Train Loss: 0.9510% | Train Acc: 74.12% | Val Loss: 0.7206% | Val Acc: 78.74% | Val Acc (Test Head Only): 83.57%
Epoch 40 | LR: 2.50e-04 | Train Loss: 0.9478% | Train Acc: 74.03% | Val Loss: 0.6825% | Val Acc: 79.79% | Val Acc (Test Head Only): 84.69%
Epoch 41 | LR: 2.50e-04 | Train Loss: 0.9232% | Train Acc: 74.82% | Val Loss: 0.6728% | Val Acc: 80.16% | Val Acc (Test Head Only): 84.44%
Epoch 42 | LR: 2.50e-04 | Train Loss: 0.9308% | Train Acc: 74.52% | Val Loss: 0.7160% | Val Acc: 79.08% | Val Acc (Test Head Only): 83.77%
Epoch 43 | LR: 2.50e-04 | Train Loss: 0.9212% | Train Acc: 74.78% | Val Loss: 0.6597% | Val Acc: 80.37% | Val Acc (Test Head Only): 84.83%
Epoch 44 | LR: 2.50e-04 | Train Loss: 0.9216% | Train Acc: 74.86% | Val Loss: 0.6825% | Val Acc: 80.17% | Val Acc (Test Head Only): 84.69%
Epoch 45 | LR: 2.50e-04 | Train Loss: 0.9196% | Train Acc: 74.87% | Val Loss: 0.6484% | Val Acc: 80.43% | Val Acc (Test Head Only): 85.12%
Epoch 46 | LR: 2.50e-04 | Train Loss: 0.9137% | Train Acc: 75.23% | Val Loss: 0.6639% | Val Acc: 80.35% | Val Acc (Test Head Only): 84.90%
Epoch 47 | LR: 2.50e-04 | Train Loss: 0.9135% | Train Acc: 75.10% | Val Loss: 0.6422% | Val Acc: 80.76% | Val Acc (Test Head Only): 85.09%
Epoch 48 | LR: 2.50e-04 | Train Loss: 0.8970% | Train Acc: 75.21% | Val Loss: 0.6580% | Val Acc: 80.33% | Val Acc (Test Head Only): 84.58%
Epoch 49 | LR: 1.25e-04 | Train Loss: 0.8989% | Train Acc: 75.25% | Val Loss: 0.6963% | Val Acc: 79.19% | Val Acc (Test Head Only): 83.83%
Epoch 50 | LR: 1.25e-04 | Train Loss: 0.8239% | Train Acc: 77.60% | Val Loss: 0.6486% | Val Acc: 81.09% | Val Acc (Test Head Only): 85.65%
Epoch 51 | LR: 1.25e-04 | Train Loss: 0.8058% | Train Acc: 78.05% | Val Loss: 0.6291% | Val Acc: 81.27% | Val Acc (Test Head Only): 85.99%
Epoch 52 | LR: 1.25e-04 | Train Loss: 0.8002% | Train Acc: 78.11% | Val Loss: 0.6407% | Val Acc: 81.01% | Val Acc (Test Head Only): 85.69%
Epoch 53 | LR: 1.25e-04 | Train Loss: 0.7949% | Train Acc: 78.18% | Val Loss: 0.6157% | Val Acc: 81.63% | Val Acc (Test Head Only): 86.12%
Epoch 54 | LR: 1.25e-04 | Train Loss: 0.8006% | Train Acc: 78.23% | Val Loss: 0.5920% | Val Acc: 82.45% | Val Acc (Test Head Only): 86.89%
Epoch 55 | LR: 1.25e-04 | Train Loss: 0.8011% | Train Acc: 78.09% | Val Loss: 0.6352% | Val Acc: 81.15% | Val Acc (Test Head Only): 85.60%
Epoch 56 | LR: 1.25e-04 | Train Loss: 0.7927% | Train Acc: 78.33% | Val Loss: 0.6183% | Val Acc: 81.47% | Val Acc (Test Head Only): 86.04%
Epoch 57 | LR: 1.25e-04 | Train Loss: 0.7952% | Train Acc: 78.30% | Val Loss: 0.5990% | Val Acc: 82.17% | Val Acc (Test Head Only): 86.60%
Epoch 58 | LR: 6.25e-05 | Train Loss: 0.7880% | Train Acc: 78.61% | Val Loss: 0.6249% | Val Acc: 81.39% | Val Acc (Test Head Only): 86.18%
Epoch 59 | LR: 6.25e-05 | Train Loss: 0.7511% | Train Acc: 79.76% | Val Loss: 0.5902% | Val Acc: 82.22% | Val Acc (Test Head Only): 86.76%
Epoch 60 | LR: 6.25e-05 | Train Loss: 0.7365% | Train Acc: 80.15% | Val Loss: 0.5621% | Val Acc: 83.11% | Val Acc (Test Head Only): 87.51%
Epoch 61 | LR: 6.25e-05 | Train Loss: 0.7341% | Train Acc: 79.92% | Val Loss: 0.5960% | Val Acc: 82.12% | Val Acc (Test Head Only): 86.62%
Epoch 62 | LR: 6.25e-05 | Train Loss: 0.7397% | Train Acc: 79.94% | Val Loss: 0.5859% | Val Acc: 82.64% | Val Acc (Test Head Only): 86.93%
Epoch 63 | LR: 6.25e-05 | Train Loss: 0.7337% | Train Acc: 80.01% | Val Loss: 0.5792% | Val Acc: 82.75% | Val Acc (Test Head Only): 87.08%
Epoch 64 | LR: 3.13e-05 | Train Loss: 0.7229% | Train Acc: 80.11% | Val Loss: 0.5799% | Val Acc: 82.60% | Val Acc (Test Head Only): 87.04%
Epoch 65 | LR: 3.13e-05 | Train Loss: 0.7145% | Train Acc: 80.62% | Val Loss: 0.5840% | Val Acc: 82.56% | Val Acc (Test Head Only): 86.85%
Epoch 66 | LR: 3.13e-05 | Train Loss: 0.7105% | Train Acc: 80.59% | Val Loss: 0.5550% | Val Acc: 83.28% | Val Acc (Test Head Only): 87.37%
→ Early stopping triggered after 6 epochs without improvement.
[Seed 44] Test Accuracy on Target Sign Subset (fc_test, test subset): 85.1490%
[Seed 44] Best Val Test Head Acc: 87.5111
[OK] Wrote sparse confusion parquet → logs_0.001_reg_64_batch_size_0.0005_lr_init_he_masked_final_v1/size_40000/test_200/train_300/seed_44/cm_size40000_train300_test200_seed44_fc-train.parquet with 2387 rows
[OK] Wrote sparse confusion parquet → logs_0.001_reg_64_batch_size_0.0005_lr_init_he_masked_final_v1/size_40000/test_200/train_300/seed_44/cm_size40000_train300_test200_seed44_fc-test-subset.parquet with 853 rows
[Seed 44] Test Accuracy on all Signs Trained (fc_train, all test): 80.6638%
[Seed 44] Best Val Train Head Acc: 83.1127
[Seed 44] Best Train Accuracy: 80.1500


=== Training Summary ===
train_acc: [0.3775, 0.545, 2.4375, 9.8325, 19.8625, 28.6825, 35.715, 41.0725, 45.415, 48.73, 51.24, 53.2175, 55.3425, 57.0775, 58.515, 59.2725, 60.3225, 61.46, 62.105, 62.6275, 63.245, 64.155, 64.6925, 65.06, 65.4425, 65.82, 66.55, 66.3, 67.17, 67.2625, 67.485, 67.58, 67.9075, 68.01, 68.5125, 68.8325, 72.925, 74.155, 73.4225, 74.1175, 74.0275, 74.8175, 74.52, 74.785, 74.865, 74.8725, 75.235, 75.0975, 75.2125, 75.255, 77.5975, 78.05, 78.1075, 78.1775, 78.23, 78.095, 78.3325, 78.2975, 78.605, 79.76, 80.15, 79.925, 79.94, 80.01, 80.105, 80.625, 80.5875]

val_acc: [0.573699954923575, 0.8810392164897759, 7.765438675572676, 21.841576855304677, 32.164078187108146, 41.437528172765646, 47.100766299225505, 54.644920706470515, 56.89054624431422, 59.27959677088882, 60.0663852804983, 63.483997869114454, 66.54509691431382, 67.36057042166946, 67.01635044871533, 68.44650247920337, 68.78662459533663, 69.16362742285784, 69.61439167315494, 70.34381018727206, 72.56484858419047, 71.21665369012007, 72.05261648158013, 71.6592222267754, 73.54013850756054, 74.52772200139327, 73.05659140269638, 73.74912920542556, 73.29836495512846, 74.69983198787034, 73.74093349178379, 75.37597836331598, 74.88423554481007, 73.5729213621276, 74.53181985821415, 75.38007622013687, 79.25664877269188, 79.14600663852805, 79.32221448182601, 78.73622095643978, 79.78527230258575, 80.16227513010695, 79.08044092939393, 80.37126582797197, 80.17047084374872, 80.43273368028521, 80.35487440068844, 80.76466008277671, 80.33028725976314, 79.18698520673688, 81.08839077162644, 81.26869647174527, 81.00643363520878, 81.62521001516207, 82.44887923615948, 81.1457607671188, 81.46949145596852, 82.17432282916035, 81.38753431955088, 82.21939925419007, 83.11273204114248, 82.12105069048887, 82.64147850674098, 82.74802278408393, 82.59640208171126, 82.5636192271442, 83.28074417079867]

val_testhead_acc: [0.3021506013389419, 1.4337342259612535, 10.800402867468453, 26.75513952248356, 37.804372296937025, 48.42111499496416, 53.83612773268558, 61.11144025119972, 62.959890988802655, 65.91622726464838, 66.05249126133064, 69.64275134782866, 72.39172936785354, 72.89531370341845, 72.48059719177677, 73.6358789027786, 74.51270809882102, 75.5258012915457, 75.54949937792523, 76.10047988624919, 78.06149653415487, 76.85881865039399, 77.62900645772854, 76.43225309556253, 78.53545826174536, 80.01066413887078, 78.1444398364832, 79.30564606907993, 78.92647668700752, 80.29504117542508, 78.98572190295634, 79.92179631494757, 80.01066413887078, 78.902778600628, 79.57817406244446, 81.04153089638012, 84.53107411576515, 84.03933882339001, 84.2940932519699, 83.5713016173944, 84.68511167723206, 84.44220629184193, 83.77273535162036, 84.83322471710409, 84.69103619882695, 85.12352627525327, 84.90431897624266, 85.08797914568399, 84.5784702885242, 83.83198056756918, 85.6508086971977, 85.99443094970081, 85.68635582676698, 86.11884590319332, 86.89495823212276, 85.60341252443865, 86.03590260086499, 86.60465667397358, 86.17809111914212, 86.76461875703536, 87.5111084779904, 86.62243023875823, 86.93050536169204, 87.07861840156407, 87.0371467503999, 86.85348658095859, 87.36891995971325]

val_loss: [6.287538849544912, 5.629481390470931, 4.186797321758685, 3.253460478080187, 2.674847411888572, 2.2541613343338134, 2.015242346631637, 1.68297054386772, 1.5906814145186015, 1.47485863587966, 1.4174853739804705, 1.2996004962317353, 1.1690366560722167, 1.1623451463810681, 1.175445626545347, 1.122319461961987, 1.086257248199734, 1.0951320512570382, 1.047302822834575, 1.0149659000644575, 0.9483696997216973, 1.0024504163702634, 0.9640219941108152, 0.97793130764623, 0.9186669974201445, 0.8674486381169426, 0.929626430653453, 0.9115502300777528, 0.9049328751497199, 0.8535832289090505, 0.9000843970476543, 0.8408739194393021, 0.8712256174715153, 0.9162057663619321, 0.8810590451034235, 0.8444051983287792, 0.6982560840995615, 0.7157175790817577, 0.7036858350704113, 0.7205745420465507, 0.6825205688202415, 0.6728259698438853, 0.716034698375438, 0.6596763119469733, 0.6824501273656768, 0.6484258044417196, 0.663877282573303, 0.642182457531563, 0.6579999031456055, 0.6963020019739743, 0.6486433782484895, 0.6290745728060744, 0.640748168288042, 0.615691288960682, 0.5920221057943705, 0.6352203403179486, 0.6182653376964576, 0.5990329321762511, 0.6249340518583006, 0.5902353104365603, 0.5621153532259436, 0.5960133612847145, 0.5859183166372245, 0.5792436507428879, 0.5799475943573732, 0.5840238553380612, 0.5550490517780018]

train_loss: [5.831884228515625, 5.6677398681640625, 5.0393525390625, 4.102971911621093, 3.433581336975098, 2.93230768737793, 2.5946783294677735, 2.3384868139266968, 2.1489697698593138, 1.992701630973816, 1.8806919799804687, 1.792957315826416, 1.7109543807983398, 1.6417333250045776, 1.5870437044143677, 1.5310909651756286, 1.50234676322937, 1.4510355115890503, 1.4214288478851318, 1.389299182510376, 1.3582102962493896, 1.3377054958343506, 1.31726240234375, 1.2888289932250976, 1.2832717748641969, 1.2754504870414733, 1.2408262954711915, 1.2411148500442506, 1.2153049133300782, 1.210096502304077, 1.1972145780563355, 1.2029929955482483, 1.1830487769126892, 1.176628433418274, 1.1645965891838073, 1.1464532638549805, 0.9944783088684082, 0.9563941020011902, 0.9717576059341431, 0.9510094648838043, 0.9477515705108642, 0.9231674760818481, 0.9307566487789154, 0.9212302073478699, 0.9215805054187775, 0.9195679353713989, 0.9137099061489106, 0.9134507667064666, 0.8969677487373352, 0.8988744760036469, 0.8239179243087769, 0.8057975856781006, 0.8002111365318298, 0.7949329813957214, 0.8006447739601136, 0.8011470592975617, 0.7927371651649475, 0.7952130219936371, 0.7879838888645172, 0.7511165131092071, 0.736463370513916, 0.7341417487621308, 0.7396681030273438, 0.7337385704994202, 0.7228622598171234, 0.7145088452339172, 0.7104984457969665]

val_testhead_loss: [6.020422814122464, 5.236457381318252, 3.7821876529240694, 2.8356854186195624, 2.289220778084287, 1.897341407964817, 1.687942710689928, 1.3867057963311442, 1.3248128962005454, 1.217599966986653, 1.1572266183261644, 1.0737090291298357, 0.9542921015020442, 0.9555710041750395, 0.9681331194582776, 0.92068697106846, 0.8855525762102278, 0.8787840112696835, 0.8466090598397504, 0.8246029827297281, 0.7665728792699142, 0.8127779625371647, 0.7759098658291068, 0.8125381294203791, 0.7513830123251949, 0.6933038008619847, 0.7617607494485457, 0.7373935439567005, 0.7226854321342755, 0.6794950732373889, 0.7217028375428762, 0.6934388680689793, 0.6926460128004527, 0.7389830798113739, 0.7130989837726998, 0.6647605016157521, 0.5405090115812126, 0.5622563874714818, 0.5551554629256625, 0.5758144334033666, 0.5317753976818664, 0.5343466382075334, 0.5684275514894176, 0.5189686214592271, 0.5384955331007799, 0.5028473384304488, 0.5217713989068903, 0.508457104674313, 0.5268930774662116, 0.5542117358719514, 0.5068063535190418, 0.48766206474681767, 0.5000094128001802, 0.48230892619421234, 0.4519296648302267, 0.49712095362709713, 0.479154526557895, 0.46837794777641323, 0.4824130454060555, 0.45741799850198034, 0.4337832307640223, 0.4620512631310234, 0.4529898759017158, 0.4471409140673709, 0.44787695507282077, 0.4534791776755599, 0.428288651541007]

best_val_loss: 0.5621153532259436

best_train_loss: 0.736463370513916

best_val_testhead_loss: 0.4337832307640223

test_acc_fc_train: 80.66378066378067

test_acc_fc_test: 85.14902363823226

best_val_acc: 83.11273204114248

best_train_acc: 80.15

best_val_testhead_acc: 87.5111084779904

best_epoch: 60

=== Artifacts ===
Seed directory: seed_44
Confusion (train head) Parquet: seed_44/cm_size40000_train300_test200_seed44_fc-train.parquet
Confusion (test head) Parquet: seed_44/cm_size40000_train300_test200_seed44_fc-test-subset.parquet
