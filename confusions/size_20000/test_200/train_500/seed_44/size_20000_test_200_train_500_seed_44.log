Device: cuda

=== Hyperparameters ===
input_features: 21
num_coords: 3
max_frames: 400
batch_size: 64
epochs: 100
lr: 0.0005
weight_decay: 0.001
patience: 6
lr_scheduler_patience: 3
cooldown: 0
min_delta: 0.01
device: cuda
[DEBUG] Model and optimizer setup complete. About to start training loop.

=== Config: 500 train signs | 200 test signs | Seed: 44 | Size: 20000 ===

Normalization Stats done
Train Set done
Val Set done
Test Set done
Test Subset Set done
Train Loader done
Val Loader done
Test Loader done
Test Subset Loader done
[Seed 44] Train Set Size: 20000
[Seed 44] Val Set Size: 41238, Test Set Size: 38514
Applied Xavier weight initialization
Total number of parameters: 2304700
Model compiled with torch.compile

=== Model Architecture ===
OptimizedModule(
  (_orig_mod): TransformerClassifier(
    (embedding): Linear(in_features=63, out_features=256, bias=True)
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.05, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-3): 4 x TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (linear1): Linear(in_features=256, out_features=512, bias=True)
          (dropout): Dropout(p=0.3, inplace=False)
          (linear2): Linear(in_features=512, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.3, inplace=False)
          (dropout2): Dropout(p=0.3, inplace=False)
        )
      )
    )
    (pooling): AdaptiveAvgPool1d(output_size=1)
    (final_dropout): Dropout(p=0.2, inplace=False)
    (fc_train): Linear(in_features=256, out_features=500, bias=True)
    (fc_test): Linear(in_features=256, out_features=200, bias=True)
  )
)
/home/tdahake3/miniconda3/envs/fs_dl2/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
scheduler initialized
Epoch 00 | LR: 5.00e-04 | Train Loss: 6.4210% | Train Acc: 0.18% | Val Loss: 6.8603% | Val Acc: 0.10% | Val Acc (Test Head Only): 0.30%
Epoch 01 | LR: 5.00e-04 | Train Loss: 6.2956% | Train Acc: 0.19% | Val Loss: 6.7681% | Val Acc: 0.12% | Val Acc (Test Head Only): 0.91%
Epoch 02 | LR: 5.00e-04 | Train Loss: 6.2693% | Train Acc: 0.19% | Val Loss: 6.6203% | Val Acc: 0.31% | Val Acc (Test Head Only): 0.85%
Epoch 03 | LR: 5.00e-04 | Train Loss: 6.2259% | Train Acc: 0.26% | Val Loss: 6.3786% | Val Acc: 0.68% | Val Acc (Test Head Only): 0.88%
Epoch 04 | LR: 5.00e-04 | Train Loss: 6.0167% | Train Acc: 0.45% | Val Loss: 6.0789% | Val Acc: 0.70% | Val Acc (Test Head Only): 1.61%
Epoch 05 | LR: 5.00e-04 | Train Loss: 5.8251% | Train Acc: 0.65% | Val Loss: 5.7195% | Val Acc: 1.19% | Val Acc (Test Head Only): 2.66%
Epoch 06 | LR: 5.00e-04 | Train Loss: 5.6137% | Train Acc: 1.11% | Val Loss: 5.3947% | Val Acc: 1.57% | Val Acc (Test Head Only): 3.28%
Epoch 07 | LR: 5.00e-04 | Train Loss: 5.4219% | Train Acc: 1.56% | Val Loss: 5.1493% | Val Acc: 2.39% | Val Acc (Test Head Only): 5.73%
Epoch 08 | LR: 5.00e-04 | Train Loss: 5.2518% | Train Acc: 2.34% | Val Loss: 4.8739% | Val Acc: 4.23% | Val Acc (Test Head Only): 8.47%
Epoch 09 | LR: 5.00e-04 | Train Loss: 5.0194% | Train Acc: 3.49% | Val Loss: 4.6097% | Val Acc: 5.91% | Val Acc (Test Head Only): 11.65%
Epoch 10 | LR: 5.00e-04 | Train Loss: 4.7571% | Train Acc: 5.08% | Val Loss: 4.2505% | Val Acc: 8.57% | Val Acc (Test Head Only): 16.73%
Epoch 11 | LR: 5.00e-04 | Train Loss: 4.5254% | Train Acc: 7.14% | Val Loss: 4.0852% | Val Acc: 10.82% | Val Acc (Test Head Only): 19.75%
Epoch 12 | LR: 5.00e-04 | Train Loss: 4.3335% | Train Acc: 8.80% | Val Loss: 3.8951% | Val Acc: 13.74% | Val Acc (Test Head Only): 21.43%
Epoch 13 | LR: 5.00e-04 | Train Loss: 4.1655% | Train Acc: 10.84% | Val Loss: 3.6387% | Val Acc: 16.78% | Val Acc (Test Head Only): 27.10%
Epoch 14 | LR: 5.00e-04 | Train Loss: 4.0304% | Train Acc: 12.22% | Val Loss: 3.5512% | Val Acc: 17.50% | Val Acc (Test Head Only): 28.84%
Epoch 15 | LR: 5.00e-04 | Train Loss: 3.8873% | Train Acc: 14.06% | Val Loss: 3.3524% | Val Acc: 21.06% | Val Acc (Test Head Only): 31.56%
Epoch 16 | LR: 5.00e-04 | Train Loss: 3.7478% | Train Acc: 16.27% | Val Loss: 3.2220% | Val Acc: 23.58% | Val Acc (Test Head Only): 36.20%
Epoch 17 | LR: 5.00e-04 | Train Loss: 3.6070% | Train Acc: 18.89% | Val Loss: 3.0530% | Val Acc: 27.31% | Val Acc (Test Head Only): 40.01%
Epoch 18 | LR: 5.00e-04 | Train Loss: 3.4572% | Train Acc: 21.32% | Val Loss: 2.9776% | Val Acc: 27.72% | Val Acc (Test Head Only): 40.27%
Epoch 19 | LR: 5.00e-04 | Train Loss: 3.3442% | Train Acc: 23.11% | Val Loss: 2.8895% | Val Acc: 29.01% | Val Acc (Test Head Only): 42.85%
Epoch 20 | LR: 5.00e-04 | Train Loss: 3.1947% | Train Acc: 25.86% | Val Loss: 2.7710% | Val Acc: 31.22% | Val Acc (Test Head Only): 44.42%
Epoch 21 | LR: 5.00e-04 | Train Loss: 3.0950% | Train Acc: 27.83% | Val Loss: 2.6366% | Val Acc: 35.06% | Val Acc (Test Head Only): 48.18%
Epoch 22 | LR: 5.00e-04 | Train Loss: 3.0054% | Train Acc: 29.28% | Val Loss: 2.5643% | Val Acc: 35.59% | Val Acc (Test Head Only): 48.66%
Epoch 23 | LR: 5.00e-04 | Train Loss: 2.9232% | Train Acc: 30.89% | Val Loss: 2.4350% | Val Acc: 38.17% | Val Acc (Test Head Only): 52.14%
Epoch 24 | LR: 5.00e-04 | Train Loss: 2.8380% | Train Acc: 32.12% | Val Loss: 2.3814% | Val Acc: 38.86% | Val Acc (Test Head Only): 53.34%
Epoch 25 | LR: 5.00e-04 | Train Loss: 2.7590% | Train Acc: 33.87% | Val Loss: 2.2819% | Val Acc: 41.14% | Val Acc (Test Head Only): 54.77%
Epoch 26 | LR: 5.00e-04 | Train Loss: 2.7050% | Train Acc: 34.96% | Val Loss: 2.2355% | Val Acc: 41.76% | Val Acc (Test Head Only): 55.67%
Epoch 27 | LR: 5.00e-04 | Train Loss: 2.6382% | Train Acc: 36.29% | Val Loss: 2.2411% | Val Acc: 42.00% | Val Acc (Test Head Only): 55.63%
Epoch 28 | LR: 5.00e-04 | Train Loss: 2.5657% | Train Acc: 37.10% | Val Loss: 2.1831% | Val Acc: 42.84% | Val Acc (Test Head Only): 57.09%
Epoch 29 | LR: 5.00e-04 | Train Loss: 2.5229% | Train Acc: 38.30% | Val Loss: 2.1564% | Val Acc: 43.53% | Val Acc (Test Head Only): 58.13%
Epoch 30 | LR: 5.00e-04 | Train Loss: 2.4744% | Train Acc: 39.09% | Val Loss: 2.0624% | Val Acc: 45.54% | Val Acc (Test Head Only): 59.85%
Epoch 31 | LR: 5.00e-04 | Train Loss: 2.4110% | Train Acc: 40.72% | Val Loss: 2.1773% | Val Acc: 43.44% | Val Acc (Test Head Only): 56.95%
Epoch 32 | LR: 5.00e-04 | Train Loss: 2.3580% | Train Acc: 41.64% | Val Loss: 2.0511% | Val Acc: 45.98% | Val Acc (Test Head Only): 59.52%
Epoch 33 | LR: 5.00e-04 | Train Loss: 2.3367% | Train Acc: 41.80% | Val Loss: 1.9967% | Val Acc: 47.58% | Val Acc (Test Head Only): 61.12%
Epoch 34 | LR: 5.00e-04 | Train Loss: 2.2811% | Train Acc: 43.58% | Val Loss: 2.0142% | Val Acc: 46.76% | Val Acc (Test Head Only): 60.51%
Epoch 35 | LR: 5.00e-04 | Train Loss: 2.2183% | Train Acc: 44.41% | Val Loss: 1.9189% | Val Acc: 49.07% | Val Acc (Test Head Only): 62.46%
Epoch 36 | LR: 5.00e-04 | Train Loss: 2.1808% | Train Acc: 45.70% | Val Loss: 1.8406% | Val Acc: 51.40% | Val Acc (Test Head Only): 64.93%
Epoch 37 | LR: 5.00e-04 | Train Loss: 2.1482% | Train Acc: 46.59% | Val Loss: 1.8513% | Val Acc: 50.96% | Val Acc (Test Head Only): 64.69%
Epoch 38 | LR: 5.00e-04 | Train Loss: 2.1264% | Train Acc: 47.50% | Val Loss: 1.9262% | Val Acc: 48.89% | Val Acc (Test Head Only): 61.96%
Epoch 39 | LR: 5.00e-04 | Train Loss: 2.0962% | Train Acc: 47.67% | Val Loss: 1.8657% | Val Acc: 50.11% | Val Acc (Test Head Only): 64.72%
Epoch 40 | LR: 5.00e-04 | Train Loss: 2.0493% | Train Acc: 48.80% | Val Loss: 1.7835% | Val Acc: 52.48% | Val Acc (Test Head Only): 66.63%
Epoch 41 | LR: 5.00e-04 | Train Loss: 2.0219% | Train Acc: 49.28% | Val Loss: 1.6571% | Val Acc: 54.72% | Val Acc (Test Head Only): 67.88%
Epoch 42 | LR: 5.00e-04 | Train Loss: 2.0215% | Train Acc: 49.34% | Val Loss: 1.6138% | Val Acc: 56.04% | Val Acc (Test Head Only): 69.07%
Epoch 43 | LR: 5.00e-04 | Train Loss: 1.9806% | Train Acc: 50.08% | Val Loss: 1.9000% | Val Acc: 50.29% | Val Acc (Test Head Only): 64.61%
Epoch 44 | LR: 5.00e-04 | Train Loss: 1.9561% | Train Acc: 50.20% | Val Loss: 1.7848% | Val Acc: 52.24% | Val Acc (Test Head Only): 65.69%
Epoch 45 | LR: 5.00e-04 | Train Loss: 1.9349% | Train Acc: 51.08% | Val Loss: 1.6088% | Val Acc: 55.57% | Val Acc (Test Head Only): 69.64%
Epoch 46 | LR: 2.50e-04 | Train Loss: 1.9008% | Train Acc: 51.57% | Val Loss: 1.7138% | Val Acc: 54.37% | Val Acc (Test Head Only): 67.21%
Epoch 47 | LR: 2.50e-04 | Train Loss: 1.7238% | Train Acc: 56.63% | Val Loss: 1.4431% | Val Acc: 60.31% | Val Acc (Test Head Only): 73.16%
Epoch 48 | LR: 2.50e-04 | Train Loss: 1.6599% | Train Acc: 57.59% | Val Loss: 1.4444% | Val Acc: 60.40% | Val Acc (Test Head Only): 73.37%
Epoch 49 | LR: 2.50e-04 | Train Loss: 1.6383% | Train Acc: 57.88% | Val Loss: 1.4755% | Val Acc: 59.14% | Val Acc (Test Head Only): 71.89%
Epoch 50 | LR: 2.50e-04 | Train Loss: 1.6061% | Train Acc: 58.52% | Val Loss: 1.4417% | Val Acc: 60.62% | Val Acc (Test Head Only): 72.43%
Epoch 51 | LR: 2.50e-04 | Train Loss: 1.5958% | Train Acc: 58.98% | Val Loss: 1.4087% | Val Acc: 60.84% | Val Acc (Test Head Only): 73.80%
Epoch 52 | LR: 2.50e-04 | Train Loss: 1.6045% | Train Acc: 58.90% | Val Loss: 1.4067% | Val Acc: 60.99% | Val Acc (Test Head Only): 73.77%
Epoch 53 | LR: 2.50e-04 | Train Loss: 1.5670% | Train Acc: 59.56% | Val Loss: 1.3960% | Val Acc: 61.15% | Val Acc (Test Head Only): 74.45%
Epoch 54 | LR: 2.50e-04 | Train Loss: 1.5571% | Train Acc: 59.98% | Val Loss: 1.3684% | Val Acc: 61.80% | Val Acc (Test Head Only): 74.37%
Epoch 55 | LR: 2.50e-04 | Train Loss: 1.5478% | Train Acc: 60.09% | Val Loss: 1.3578% | Val Acc: 62.31% | Val Acc (Test Head Only): 74.60%
Epoch 56 | LR: 2.50e-04 | Train Loss: 1.5386% | Train Acc: 60.44% | Val Loss: 1.3857% | Val Acc: 61.51% | Val Acc (Test Head Only): 74.43%
Epoch 57 | LR: 2.50e-04 | Train Loss: 1.5310% | Train Acc: 60.47% | Val Loss: 1.4174% | Val Acc: 60.88% | Val Acc (Test Head Only): 73.40%
Epoch 58 | LR: 2.50e-04 | Train Loss: 1.5252% | Train Acc: 60.40% | Val Loss: 1.3261% | Val Acc: 62.99% | Val Acc (Test Head Only): 75.27%
Epoch 59 | LR: 2.50e-04 | Train Loss: 1.4989% | Train Acc: 61.10% | Val Loss: 1.4463% | Val Acc: 60.01% | Val Acc (Test Head Only): 72.66%
Epoch 60 | LR: 2.50e-04 | Train Loss: 1.4993% | Train Acc: 61.11% | Val Loss: 1.3473% | Val Acc: 62.64% | Val Acc (Test Head Only): 75.05%
Epoch 61 | LR: 2.50e-04 | Train Loss: 1.4893% | Train Acc: 61.16% | Val Loss: 1.3556% | Val Acc: 62.79% | Val Acc (Test Head Only): 74.88%
Epoch 62 | LR: 1.25e-04 | Train Loss: 1.4899% | Train Acc: 61.24% | Val Loss: 1.3905% | Val Acc: 61.96% | Val Acc (Test Head Only): 74.72%
Epoch 63 | LR: 1.25e-04 | Train Loss: 1.3796% | Train Acc: 64.41% | Val Loss: 1.2914% | Val Acc: 64.12% | Val Acc (Test Head Only): 76.76%
Epoch 64 | LR: 1.25e-04 | Train Loss: 1.3367% | Train Acc: 65.12% | Val Loss: 1.2785% | Val Acc: 64.43% | Val Acc (Test Head Only): 76.96%
Epoch 65 | LR: 1.25e-04 | Train Loss: 1.3424% | Train Acc: 65.17% | Val Loss: 1.2800% | Val Acc: 64.07% | Val Acc (Test Head Only): 76.83%
Epoch 66 | LR: 1.25e-04 | Train Loss: 1.3340% | Train Acc: 65.58% | Val Loss: 1.2036% | Val Acc: 66.21% | Val Acc (Test Head Only): 78.28%
Epoch 67 | LR: 1.25e-04 | Train Loss: 1.3380% | Train Acc: 65.21% | Val Loss: 1.2764% | Val Acc: 64.69% | Val Acc (Test Head Only): 76.77%
Epoch 68 | LR: 1.25e-04 | Train Loss: 1.3090% | Train Acc: 66.09% | Val Loss: 1.2511% | Val Acc: 64.94% | Val Acc (Test Head Only): 77.34%
Epoch 69 | LR: 1.25e-04 | Train Loss: 1.3152% | Train Acc: 65.98% | Val Loss: 1.2310% | Val Acc: 65.65% | Val Acc (Test Head Only): 77.87%
Epoch 70 | LR: 6.25e-05 | Train Loss: 1.3236% | Train Acc: 66.08% | Val Loss: 1.2158% | Val Acc: 65.82% | Val Acc (Test Head Only): 77.98%
Epoch 71 | LR: 6.25e-05 | Train Loss: 1.2680% | Train Acc: 67.36% | Val Loss: 1.1963% | Val Acc: 66.49% | Val Acc (Test Head Only): 78.51%
Epoch 72 | LR: 6.25e-05 | Train Loss: 1.2498% | Train Acc: 67.50% | Val Loss: 1.1806% | Val Acc: 66.80% | Val Acc (Test Head Only): 78.66%
Epoch 73 | LR: 6.25e-05 | Train Loss: 1.2354% | Train Acc: 67.90% | Val Loss: 1.1893% | Val Acc: 66.85% | Val Acc (Test Head Only): 78.80%
Epoch 74 | LR: 6.25e-05 | Train Loss: 1.2327% | Train Acc: 68.28% | Val Loss: 1.1951% | Val Acc: 66.38% | Val Acc (Test Head Only): 78.06%
Epoch 75 | LR: 6.25e-05 | Train Loss: 1.2198% | Train Acc: 68.30% | Val Loss: 1.1913% | Val Acc: 66.78% | Val Acc (Test Head Only): 78.61%
Epoch 76 | LR: 3.13e-05 | Train Loss: 1.2262% | Train Acc: 68.64% | Val Loss: 1.1784% | Val Acc: 67.06% | Val Acc (Test Head Only): 78.68%
Epoch 77 | LR: 3.13e-05 | Train Loss: 1.2103% | Train Acc: 68.81% | Val Loss: 1.1683% | Val Acc: 67.10% | Val Acc (Test Head Only): 78.93%
Epoch 78 | LR: 3.13e-05 | Train Loss: 1.1996% | Train Acc: 68.70% | Val Loss: 1.1658% | Val Acc: 67.12% | Val Acc (Test Head Only): 78.98%
Epoch 79 | LR: 3.13e-05 | Train Loss: 1.1988% | Train Acc: 69.24% | Val Loss: 1.1762% | Val Acc: 67.06% | Val Acc (Test Head Only): 78.80%
Epoch 80 | LR: 3.13e-05 | Train Loss: 1.1939% | Train Acc: 69.15% | Val Loss: 1.1581% | Val Acc: 67.54% | Val Acc (Test Head Only): 79.26%
Epoch 81 | LR: 3.13e-05 | Train Loss: 1.1917% | Train Acc: 69.08% | Val Loss: 1.1527% | Val Acc: 67.71% | Val Acc (Test Head Only): 79.35%
Epoch 82 | LR: 3.13e-05 | Train Loss: 1.1941% | Train Acc: 69.24% | Val Loss: 1.1840% | Val Acc: 66.87% | Val Acc (Test Head Only): 78.62%
Epoch 83 | LR: 3.13e-05 | Train Loss: 1.1985% | Train Acc: 69.23% | Val Loss: 1.1743% | Val Acc: 67.02% | Val Acc (Test Head Only): 78.90%
Epoch 84 | LR: 3.13e-05 | Train Loss: 1.1775% | Train Acc: 69.55% | Val Loss: 1.1635% | Val Acc: 67.45% | Val Acc (Test Head Only): 79.21%
Epoch 85 | LR: 1.56e-05 | Train Loss: 1.1851% | Train Acc: 69.75% | Val Loss: 1.1640% | Val Acc: 67.31% | Val Acc (Test Head Only): 79.12%
Epoch 86 | LR: 1.56e-05 | Train Loss: 1.1726% | Train Acc: 69.66% | Val Loss: 1.1593% | Val Acc: 67.44% | Val Acc (Test Head Only): 79.24%
→ Early stopping triggered after 6 epochs without improvement.
[Seed 44] Test Accuracy on Target Sign Subset (fc_test, test subset): 77.8588%
[Seed 44] Best Val Test Head Acc: 79.2554
[OK] Wrote sparse confusion parquet → logs_0.001_reg_64_batch_size_0.0005_lr_init_he_masked_final_v1/size_20000/test_200/train_500/seed_44/cm_size20000_train500_test200_seed44_fc-train.parquet with 6456 rows
[OK] Wrote sparse confusion parquet → logs_0.001_reg_64_batch_size_0.0005_lr_init_he_masked_final_v1/size_20000/test_200/train_500/seed_44/cm_size20000_train500_test200_seed44_fc-test-subset.parquet with 671 rows
[Seed 44] Test Accuracy on all Signs Trained (fc_train, all test): 66.2434%
[Seed 44] Best Val Train Head Acc: 67.5396
[Seed 44] Best Train Accuracy: 69.1500


=== Training Summary ===
train_acc: [0.185, 0.19, 0.19, 0.255, 0.445, 0.645, 1.115, 1.56, 2.34, 3.49, 5.085, 7.14, 8.8, 10.84, 12.225, 14.06, 16.275, 18.895, 21.315, 23.115, 25.86, 27.83, 29.28, 30.885, 32.12, 33.87, 34.96, 36.29, 37.105, 38.3, 39.085, 40.72, 41.64, 41.795, 43.58, 44.415, 45.7, 46.595, 47.5, 47.67, 48.795, 49.28, 49.34, 50.075, 50.195, 51.075, 51.57, 56.635, 57.595, 57.885, 58.515, 58.98, 58.9, 59.565, 59.975, 60.095, 60.435, 60.47, 60.4, 61.105, 61.11, 61.16, 61.245, 64.41, 65.12, 65.165, 65.58, 65.21, 66.095, 65.985, 66.075, 67.355, 67.495, 67.9, 68.285, 68.3, 68.635, 68.81, 68.7, 69.24, 69.15, 69.08, 69.24, 69.23, 69.55, 69.755, 69.66]

val_acc: [0.10427275813570008, 0.1212473931810466, 0.30554343081623747, 0.678985401813861, 0.7032348804500703, 1.1882244531742567, 1.568941267762743, 2.39342354139386, 4.233958969882147, 5.912022891507832, 8.572190697899995, 10.82254231534022, 13.744604491003443, 16.775789320529608, 17.503273679615887, 21.060672195547795, 23.577768077986324, 27.309762840098937, 27.722003976914497, 29.00722634463359, 31.221203744119503, 35.059896212231436, 35.586109898637176, 38.16625442552985, 38.85978951452544, 41.13681555846549, 41.764877055143316, 41.9952471021873, 42.839128958727386, 43.53023909985935, 45.540520878801104, 43.44051602890538, 45.984286337843734, 47.58475192783355, 46.75541975847519, 49.06639507250594, 51.40404481303652, 50.95542945826665, 48.891798826325235, 50.11397254959019, 52.480721664484214, 54.718948542606334, 56.04054512827974, 50.29099374363451, 52.24307677384936, 55.574955138464524, 54.374605945972164, 60.313303263979826, 60.395751491342935, 59.144478393714536, 60.61642174693244, 60.844366846112806, 60.994713613657304, 61.15476017265629, 61.80222125224308, 62.30903535573985, 61.51122750860856, 60.875891168339884, 62.990445705417336, 60.00775983316359, 62.63640331732868, 62.78917503273679, 61.96469275910568, 64.11562151413744, 64.43328968427178, 64.0743974004559, 66.20592657257869, 64.69275910567923, 64.93767883990495, 65.64576361608225, 65.82278481012658, 66.48722052475871, 66.80488869489307, 66.85096270430186, 66.37809787089577, 66.77821426839323, 67.05708327270963, 67.0983073863912, 67.12013191716377, 67.05708327270963, 67.5396478975702, 67.70939424802367, 66.86551239148358, 67.02313400261895, 67.45234977447984, 67.3068529026626, 67.4353751394345]

val_testhead_acc: [0.2999647100341136, 0.905775791083402, 0.8528408422538525, 0.8822491471591577, 1.6056934478296672, 2.6643924244206563, 3.2760851664510056, 5.734619456534525, 8.469591812727915, 11.651570403481943, 16.72744383013763, 19.750617574403012, 21.42689095400541, 27.096812139748266, 28.837783790142336, 31.555111163392542, 36.20162333843077, 40.01293965415834, 40.27173273732502, 42.84790024702976, 44.424185389954125, 48.17668509587107, 48.65898129631808, 52.13504293612516, 53.34078343724268, 54.77002705564051, 55.66992118574285, 55.63463121985649, 57.09328314315963, 58.13433713680743, 59.8459004822962, 56.95212327961416, 59.52240912833784, 61.116339254205386, 60.510528173156096, 62.46323961886837, 64.93353723091401, 64.6923891306905, 61.96329843547818, 64.72179743559582, 66.62745559345959, 67.8802493824256, 69.07422656158099, 64.61004587695565, 65.69227149747088, 69.64474767674392, 67.20974003058464, 73.16198094341843, 73.37372073873662, 71.89154217150923, 72.42677332078578, 73.79720032937301, 73.77367368544877, 74.4500646982708, 74.37360310551699, 74.59710622279732, 74.43241971532761, 73.39724738266086, 75.27349723561935, 72.65615809904718, 75.04999411833901, 74.87942594988824, 74.7206211033996, 76.75567580284672, 76.96153393718386, 76.82625573461945, 78.27902599694154, 76.76743912480885, 77.34384190095282, 77.86730972826726, 77.97906128690742, 78.51429243618398, 78.65545229972945, 78.79661216327492, 78.05552287966121, 78.61428067286202, 78.67897894365369, 78.92600870485825, 78.98482531466887, 78.79661216327492, 79.25538171979767, 79.34948829549465, 78.62016233384308, 78.89660039995294, 79.20832843194918, 79.12010351723326, 79.23773673685449]

val_loss: [6.860291033527935, 6.768131979279944, 6.620274098723443, 6.378620750278869, 6.078940862411151, 5.719498797446797, 5.394703743338579, 5.149303353094697, 4.873942092882742, 4.609705115019093, 4.250455719578584, 4.08521295214747, 3.8950742227884656, 3.638689860830923, 3.5512081734267706, 3.352355474562885, 3.2220165826536715, 3.0530126282602086, 2.9776428834827375, 2.8894578066116865, 2.7710428229127118, 2.6365606625944213, 2.5643466820604233, 2.4349891225144256, 2.381427126635207, 2.2818709159719535, 2.2355438415048727, 2.241140860441417, 2.183117488057406, 2.1563591183755335, 2.0624059783400037, 2.1773385087874506, 2.0511419968286133, 1.9966920620891309, 2.0141652564118098, 1.9188571807525168, 1.840597509857963, 1.8512886466315799, 1.9261517412962337, 1.865698320343328, 1.783452333190565, 1.6570755193464635, 1.6138029606475637, 1.9000300133550334, 1.7848028342449456, 1.6088499577941924, 1.713809912440282, 1.4431301822798335, 1.4443704488986366, 1.47551504957658, 1.441661085968678, 1.4087137848556524, 1.4066517002928631, 1.3959650438031572, 1.3683607055222908, 1.3577533848816765, 1.3856848032561588, 1.417425961064069, 1.3261360787843501, 1.446257115780622, 1.347294812365724, 1.3555702860599705, 1.3904516349691465, 1.2913877726977199, 1.2785312262803172, 1.2799798263206799, 1.2036049110049147, 1.2763871248215082, 1.251077241194318, 1.2310395718279943, 1.215797564475056, 1.1963029496508697, 1.180579578545792, 1.1892984215390747, 1.1951382614643637, 1.191346600380732, 1.178385397989446, 1.1682992825002119, 1.1657873443531779, 1.1762092060160294, 1.1580714519944662, 1.1527346878892624, 1.1840404020322908, 1.1743478954165005, 1.1635102652093883, 1.16398990349971, 1.1593016760414836]

train_loss: [6.42104638671875, 6.295571875, 6.2692751953125, 6.22586005859375, 6.016717578125, 5.82509931640625, 5.61367705078125, 5.42187724609375, 5.251821533203125, 5.019402197265625, 4.75712275390625, 4.525375732421875, 4.333543725585938, 4.1655466796875, 4.03037119140625, 3.8872761596679686, 3.747753521728516, 3.6070034057617186, 3.4571809265136717, 3.34420810546875, 3.1946925689697268, 3.0949862930297853, 3.00537041015625, 2.9231931259155273, 2.8379519409179688, 2.7589857986450195, 2.70504842376709, 2.638202410125732, 2.5656680290222167, 2.5229206634521484, 2.474419432067871, 2.4110034423828126, 2.358038887023926, 2.3366842693328858, 2.2811399139404296, 2.218283382797241, 2.1807891799926757, 2.1481821269989014, 2.1264028491973876, 2.0961930164337157, 2.0492841526031493, 2.021875268173218, 2.021467292404175, 1.9806048767089843, 1.956056948852539, 1.9349122188568115, 1.9008089584350587, 1.7238408390045166, 1.6598523509979248, 1.6382500202178956, 1.6061217208862304, 1.5957688999176025, 1.6045063934326171, 1.5670310581207276, 1.5570563888549804, 1.547761665725708, 1.538594164276123, 1.5310039960861206, 1.525228411102295, 1.498941897201538, 1.4993180381774902, 1.4893338092803956, 1.4899432315826415, 1.3795731178283692, 1.3366635747909545, 1.3424089153289795, 1.3339933521270753, 1.3379674222946167, 1.3089616481781006, 1.3152022426605225, 1.3235654348373413, 1.268018286895752, 1.2497636043548583, 1.235389188194275, 1.2327347232818604, 1.2198215427398682, 1.2262324569702148, 1.210346397972107, 1.1996199838638306, 1.1987681453704835, 1.19394811668396, 1.1917481311798095, 1.194060108566284, 1.1985325540542602, 1.1774849473953246, 1.1850954933166504, 1.1726188066482544]

val_testhead_loss: [6.180789046337458, 5.9501779773854855, 5.965761505397765, 5.553915302552359, 5.2196436189732935, 4.767923319876832, 4.45792509973533, 4.141470885111324, 3.9349817974877883, 3.663137550985599, 3.319573906867199, 3.170284938284992, 3.0264020952641606, 2.748430496159055, 2.6801382886874032, 2.506709364642397, 2.373709470906576, 2.218812062920942, 2.177724274901443, 2.118329047287314, 2.003928977010559, 1.897712841452942, 1.8656943991224622, 1.7064683562151868, 1.6619652583344995, 1.60180677273893, 1.5562011643572844, 1.5853497986722842, 1.533283952698541, 1.49933603054677, 1.4203859854517173, 1.5420172298225203, 1.4313470175365548, 1.3812297997671272, 1.4078010976395177, 1.3372820440463746, 1.2283387108717003, 1.2472305128085952, 1.3791949134786723, 1.2603136833054698, 1.2042806436893954, 1.112146411090651, 1.0751206508514783, 1.2782742384899617, 1.207457987973093, 1.0598501705046037, 1.179925634089799, 0.9281036426063328, 0.9332395207354663, 0.9742524663923965, 0.9524311081404098, 0.9262121325660462, 0.9127162915766555, 0.8939159594606811, 0.9012765620434485, 0.8739648748891674, 0.9054324253298033, 0.936621140150088, 0.8492424926776323, 0.9550019667979381, 0.8820294723827942, 0.8807554627629451, 0.9173987268211351, 0.8261817084315762, 0.8188065004224652, 0.8121225314648443, 0.7615621552461141, 0.8250088017180154, 0.7996399467939167, 0.7795453512178506, 0.7770267488997363, 0.758092135098938, 0.7498305958987453, 0.7439413016804204, 0.7602312102832348, 0.763728834943268, 0.7507661908712475, 0.7407230936002204, 0.73846745389186, 0.7521140557038841, 0.7368535304593452, 0.7363593358072782, 0.7633000606356116, 0.7501562475306246, 0.7421427272411812, 0.743984684033466, 0.7368681582948373]

best_val_loss: 1.1580714519944662

best_train_loss: 1.19394811668396

best_val_testhead_loss: 0.7368535304593452

test_acc_fc_train: 66.24344394246248

test_acc_fc_test: 77.85879423795127

best_val_acc: 67.5396478975702

best_train_acc: 69.15

best_val_testhead_acc: 79.25538171979767

best_epoch: 80

=== Artifacts ===
Seed directory: seed_44
Confusion (train head) Parquet: seed_44/cm_size20000_train500_test200_seed44_fc-train.parquet
Confusion (test head) Parquet: seed_44/cm_size20000_train500_test200_seed44_fc-test-subset.parquet
