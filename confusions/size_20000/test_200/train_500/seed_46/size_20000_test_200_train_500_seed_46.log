Device: cuda

=== Hyperparameters ===
input_features: 21
num_coords: 3
max_frames: 400
batch_size: 64
epochs: 100
lr: 0.0005
weight_decay: 0.001
patience: 6
lr_scheduler_patience: 3
cooldown: 0
min_delta: 0.01
device: cuda
[DEBUG] Model and optimizer setup complete. About to start training loop.

=== Config: 500 train signs | 200 test signs | Seed: 46 | Size: 20000 ===

Normalization Stats done
Train Set done
Val Set done
Test Set done
Test Subset Set done
Train Loader done
Val Loader done
Test Loader done
Test Subset Loader done
[Seed 46] Train Set Size: 20000
[Seed 46] Val Set Size: 41311, Test Set Size: 38709
Applied Xavier weight initialization
Total number of parameters: 2304700
Model compiled with torch.compile

=== Model Architecture ===
OptimizedModule(
  (_orig_mod): TransformerClassifier(
    (embedding): Linear(in_features=63, out_features=256, bias=True)
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0.05, inplace=False)
    )
    (encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-3): 4 x TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (linear1): Linear(in_features=256, out_features=512, bias=True)
          (dropout): Dropout(p=0.3, inplace=False)
          (linear2): Linear(in_features=512, out_features=256, bias=True)
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.3, inplace=False)
          (dropout2): Dropout(p=0.3, inplace=False)
        )
      )
    )
    (pooling): AdaptiveAvgPool1d(output_size=1)
    (final_dropout): Dropout(p=0.2, inplace=False)
    (fc_train): Linear(in_features=256, out_features=500, bias=True)
    (fc_test): Linear(in_features=256, out_features=200, bias=True)
  )
)
/home/tdahake3/miniconda3/envs/fs_dl2/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
scheduler initialized
Epoch 00 | LR: 5.00e-04 | Train Loss: 6.4217% | Train Acc: 0.18% | Val Loss: 6.8624% | Val Acc: 0.13% | Val Acc (Test Head Only): 0.71%
Epoch 01 | LR: 5.00e-04 | Train Loss: 6.2937% | Train Acc: 0.17% | Val Loss: 6.7608% | Val Acc: 0.12% | Val Acc (Test Head Only): 0.45%
Epoch 02 | LR: 5.00e-04 | Train Loss: 6.2661% | Train Acc: 0.21% | Val Loss: 6.6056% | Val Acc: 0.13% | Val Acc (Test Head Only): 0.47%
Epoch 03 | LR: 5.00e-04 | Train Loss: 6.2489% | Train Acc: 0.20% | Val Loss: 6.5750% | Val Acc: 0.12% | Val Acc (Test Head Only): 0.31%
Epoch 04 | LR: 5.00e-04 | Train Loss: 6.2439% | Train Acc: 0.17% | Val Loss: 6.4666% | Val Acc: 0.23% | Val Acc (Test Head Only): 0.31%
Epoch 05 | LR: 5.00e-04 | Train Loss: 6.2321% | Train Acc: 0.21% | Val Loss: 6.3555% | Val Acc: 0.33% | Val Acc (Test Head Only): 0.73%
Epoch 06 | LR: 5.00e-04 | Train Loss: 6.1575% | Train Acc: 0.28% | Val Loss: 6.1360% | Val Acc: 0.31% | Val Acc (Test Head Only): 1.03%
Epoch 07 | LR: 5.00e-04 | Train Loss: 5.9686% | Train Acc: 0.65% | Val Loss: 5.5628% | Val Acc: 1.55% | Val Acc (Test Head Only): 3.40%
Epoch 08 | LR: 5.00e-04 | Train Loss: 5.5788% | Train Acc: 1.47% | Val Loss: 5.2075% | Val Acc: 2.31% | Val Acc (Test Head Only): 5.79%
Epoch 09 | LR: 5.00e-04 | Train Loss: 5.2964% | Train Acc: 2.33% | Val Loss: 4.9968% | Val Acc: 3.95% | Val Acc (Test Head Only): 7.84%
Epoch 10 | LR: 5.00e-04 | Train Loss: 4.9681% | Train Acc: 4.47% | Val Loss: 4.5157% | Val Acc: 7.13% | Val Acc (Test Head Only): 12.98%
Epoch 11 | LR: 5.00e-04 | Train Loss: 4.6479% | Train Acc: 6.99% | Val Loss: 4.2327% | Val Acc: 10.67% | Val Acc (Test Head Only): 17.88%
Epoch 12 | LR: 5.00e-04 | Train Loss: 4.3971% | Train Acc: 9.56% | Val Loss: 3.9680% | Val Acc: 13.99% | Val Acc (Test Head Only): 23.04%
Epoch 13 | LR: 5.00e-04 | Train Loss: 4.1651% | Train Acc: 11.95% | Val Loss: 3.7266% | Val Acc: 16.95% | Val Acc (Test Head Only): 27.61%
Epoch 14 | LR: 5.00e-04 | Train Loss: 3.9369% | Train Acc: 15.02% | Val Loss: 3.4528% | Val Acc: 20.67% | Val Acc (Test Head Only): 32.09%
Epoch 15 | LR: 5.00e-04 | Train Loss: 3.7341% | Train Acc: 17.77% | Val Loss: 3.3690% | Val Acc: 21.98% | Val Acc (Test Head Only): 33.50%
Epoch 16 | LR: 5.00e-04 | Train Loss: 3.5648% | Train Acc: 20.43% | Val Loss: 3.2345% | Val Acc: 23.62% | Val Acc (Test Head Only): 36.08%
Epoch 17 | LR: 5.00e-04 | Train Loss: 3.3919% | Train Acc: 23.22% | Val Loss: 3.1587% | Val Acc: 25.71% | Val Acc (Test Head Only): 38.40%
Epoch 18 | LR: 5.00e-04 | Train Loss: 3.2992% | Train Acc: 24.75% | Val Loss: 3.0099% | Val Acc: 28.22% | Val Acc (Test Head Only): 41.06%
Epoch 19 | LR: 5.00e-04 | Train Loss: 3.1523% | Train Acc: 27.52% | Val Loss: 2.8271% | Val Acc: 31.52% | Val Acc (Test Head Only): 44.98%
Epoch 20 | LR: 5.00e-04 | Train Loss: 3.0724% | Train Acc: 28.60% | Val Loss: 2.7103% | Val Acc: 33.59% | Val Acc (Test Head Only): 47.02%
Epoch 21 | LR: 5.00e-04 | Train Loss: 2.9556% | Train Acc: 31.07% | Val Loss: 2.7417% | Val Acc: 33.05% | Val Acc (Test Head Only): 46.73%
Epoch 22 | LR: 5.00e-04 | Train Loss: 2.8686% | Train Acc: 32.55% | Val Loss: 2.5808% | Val Acc: 36.03% | Val Acc (Test Head Only): 49.29%
Epoch 23 | LR: 5.00e-04 | Train Loss: 2.7646% | Train Acc: 34.32% | Val Loss: 2.4382% | Val Acc: 38.63% | Val Acc (Test Head Only): 52.89%
Epoch 24 | LR: 5.00e-04 | Train Loss: 2.6936% | Train Acc: 35.69% | Val Loss: 2.4847% | Val Acc: 37.99% | Val Acc (Test Head Only): 52.15%
Epoch 25 | LR: 5.00e-04 | Train Loss: 2.6159% | Train Acc: 37.78% | Val Loss: 2.3374% | Val Acc: 40.67% | Val Acc (Test Head Only): 54.55%
Epoch 26 | LR: 5.00e-04 | Train Loss: 2.5335% | Train Acc: 38.60% | Val Loss: 2.2170% | Val Acc: 43.83% | Val Acc (Test Head Only): 57.76%
Epoch 27 | LR: 5.00e-04 | Train Loss: 2.4541% | Train Acc: 40.88% | Val Loss: 2.2451% | Val Acc: 42.87% | Val Acc (Test Head Only): 56.55%
Epoch 28 | LR: 5.00e-04 | Train Loss: 2.4231% | Train Acc: 41.44% | Val Loss: 2.0729% | Val Acc: 45.60% | Val Acc (Test Head Only): 60.36%
Epoch 29 | LR: 5.00e-04 | Train Loss: 2.3656% | Train Acc: 42.02% | Val Loss: 2.1044% | Val Acc: 45.32% | Val Acc (Test Head Only): 59.76%
Epoch 30 | LR: 5.00e-04 | Train Loss: 2.3250% | Train Acc: 42.92% | Val Loss: 2.2007% | Val Acc: 43.44% | Val Acc (Test Head Only): 57.93%
Epoch 31 | LR: 5.00e-04 | Train Loss: 2.2750% | Train Acc: 44.55% | Val Loss: 2.0557% | Val Acc: 46.79% | Val Acc (Test Head Only): 61.46%
Epoch 32 | LR: 5.00e-04 | Train Loss: 2.2032% | Train Acc: 45.85% | Val Loss: 1.8944% | Val Acc: 50.16% | Val Acc (Test Head Only): 63.24%
Epoch 33 | LR: 5.00e-04 | Train Loss: 2.2026% | Train Acc: 44.80% | Val Loss: 1.9003% | Val Acc: 49.99% | Val Acc (Test Head Only): 64.39%
Epoch 34 | LR: 5.00e-04 | Train Loss: 2.1281% | Train Acc: 47.17% | Val Loss: 1.9505% | Val Acc: 49.04% | Val Acc (Test Head Only): 63.40%
Epoch 35 | LR: 5.00e-04 | Train Loss: 2.0848% | Train Acc: 47.98% | Val Loss: 1.9312% | Val Acc: 49.51% | Val Acc (Test Head Only): 63.58%
Epoch 36 | LR: 5.00e-04 | Train Loss: 2.0514% | Train Acc: 48.51% | Val Loss: 1.8445% | Val Acc: 50.72% | Val Acc (Test Head Only): 64.95%
Epoch 37 | LR: 5.00e-04 | Train Loss: 2.0429% | Train Acc: 48.80% | Val Loss: 1.8665% | Val Acc: 50.81% | Val Acc (Test Head Only): 64.17%
Epoch 38 | LR: 5.00e-04 | Train Loss: 2.0198% | Train Acc: 49.12% | Val Loss: 2.0456% | Val Acc: 47.34% | Val Acc (Test Head Only): 62.08%
Epoch 39 | LR: 5.00e-04 | Train Loss: 1.9774% | Train Acc: 50.16% | Val Loss: 1.7659% | Val Acc: 52.55% | Val Acc (Test Head Only): 66.64%
Epoch 40 | LR: 5.00e-04 | Train Loss: 1.9458% | Train Acc: 50.70% | Val Loss: 1.7283% | Val Acc: 53.55% | Val Acc (Test Head Only): 67.33%
Epoch 41 | LR: 5.00e-04 | Train Loss: 1.9387% | Train Acc: 50.96% | Val Loss: 1.6934% | Val Acc: 54.59% | Val Acc (Test Head Only): 68.97%
Epoch 42 | LR: 5.00e-04 | Train Loss: 1.9019% | Train Acc: 51.97% | Val Loss: 1.8279% | Val Acc: 51.61% | Val Acc (Test Head Only): 65.56%
Epoch 43 | LR: 5.00e-04 | Train Loss: 1.8875% | Train Acc: 52.22% | Val Loss: 1.8083% | Val Acc: 52.48% | Val Acc (Test Head Only): 66.27%
Epoch 44 | LR: 5.00e-04 | Train Loss: 1.8594% | Train Acc: 52.39% | Val Loss: 1.7036% | Val Acc: 54.38% | Val Acc (Test Head Only): 68.07%
Epoch 45 | LR: 2.50e-04 | Train Loss: 1.8435% | Train Acc: 53.16% | Val Loss: 1.6813% | Val Acc: 54.44% | Val Acc (Test Head Only): 69.15%
Epoch 46 | LR: 2.50e-04 | Train Loss: 1.6540% | Train Acc: 57.85% | Val Loss: 1.5581% | Val Acc: 57.34% | Val Acc (Test Head Only): 71.16%
Epoch 47 | LR: 2.50e-04 | Train Loss: 1.6151% | Train Acc: 58.78% | Val Loss: 1.5656% | Val Acc: 57.32% | Val Acc (Test Head Only): 71.81%
Epoch 48 | LR: 2.50e-04 | Train Loss: 1.5927% | Train Acc: 59.28% | Val Loss: 1.5246% | Val Acc: 58.54% | Val Acc (Test Head Only): 72.50%
Epoch 49 | LR: 2.50e-04 | Train Loss: 1.5815% | Train Acc: 59.47% | Val Loss: 1.5556% | Val Acc: 57.42% | Val Acc (Test Head Only): 71.65%
Epoch 50 | LR: 2.50e-04 | Train Loss: 1.5797% | Train Acc: 59.61% | Val Loss: 1.4681% | Val Acc: 59.39% | Val Acc (Test Head Only): 72.96%
Epoch 51 | LR: 2.50e-04 | Train Loss: 1.5532% | Train Acc: 60.36% | Val Loss: 1.5074% | Val Acc: 58.66% | Val Acc (Test Head Only): 72.50%
Epoch 52 | LR: 2.50e-04 | Train Loss: 1.5561% | Train Acc: 60.15% | Val Loss: 1.4875% | Val Acc: 59.01% | Val Acc (Test Head Only): 73.10%
Epoch 53 | LR: 2.50e-04 | Train Loss: 1.5333% | Train Acc: 60.47% | Val Loss: 1.4895% | Val Acc: 59.12% | Val Acc (Test Head Only): 73.03%
Epoch 54 | LR: 1.25e-04 | Train Loss: 1.5100% | Train Acc: 61.30% | Val Loss: 1.4953% | Val Acc: 59.19% | Val Acc (Test Head Only): 73.05%
Epoch 55 | LR: 1.25e-04 | Train Loss: 1.4351% | Train Acc: 63.30% | Val Loss: 1.4445% | Val Acc: 60.34% | Val Acc (Test Head Only): 74.41%
Epoch 56 | LR: 1.25e-04 | Train Loss: 1.4107% | Train Acc: 64.27% | Val Loss: 1.3924% | Val Acc: 61.49% | Val Acc (Test Head Only): 75.20%
Epoch 57 | LR: 1.25e-04 | Train Loss: 1.3902% | Train Acc: 64.13% | Val Loss: 1.3776% | Val Acc: 61.91% | Val Acc (Test Head Only): 75.37%
Epoch 58 | LR: 1.25e-04 | Train Loss: 1.3915% | Train Acc: 64.42% | Val Loss: 1.3848% | Val Acc: 61.49% | Val Acc (Test Head Only): 75.32%
Epoch 59 | LR: 1.25e-04 | Train Loss: 1.3659% | Train Acc: 64.89% | Val Loss: 1.3906% | Val Acc: 61.86% | Val Acc (Test Head Only): 75.35%
Epoch 60 | LR: 1.25e-04 | Train Loss: 1.3864% | Train Acc: 64.56% | Val Loss: 1.3978% | Val Acc: 61.27% | Val Acc (Test Head Only): 75.06%
Epoch 61 | LR: 6.25e-05 | Train Loss: 1.3751% | Train Acc: 64.61% | Val Loss: 1.3813% | Val Acc: 61.95% | Val Acc (Test Head Only): 75.15%
Epoch 62 | LR: 6.25e-05 | Train Loss: 1.3268% | Train Acc: 66.10% | Val Loss: 1.3386% | Val Acc: 62.79% | Val Acc (Test Head Only): 76.18%
Epoch 63 | LR: 6.25e-05 | Train Loss: 1.3120% | Train Acc: 66.62% | Val Loss: 1.3662% | Val Acc: 62.03% | Val Acc (Test Head Only): 75.65%
Epoch 64 | LR: 6.25e-05 | Train Loss: 1.2984% | Train Acc: 66.90% | Val Loss: 1.3475% | Val Acc: 62.72% | Val Acc (Test Head Only): 75.94%
Epoch 65 | LR: 6.25e-05 | Train Loss: 1.2967% | Train Acc: 67.00% | Val Loss: 1.3279% | Val Acc: 63.03% | Val Acc (Test Head Only): 76.54%
Epoch 66 | LR: 3.13e-05 | Train Loss: 1.3066% | Train Acc: 66.42% | Val Loss: 1.3462% | Val Acc: 62.65% | Val Acc (Test Head Only): 76.07%
Epoch 67 | LR: 3.13e-05 | Train Loss: 1.2802% | Train Acc: 67.56% | Val Loss: 1.3073% | Val Acc: 63.59% | Val Acc (Test Head Only): 76.82%
Epoch 68 | LR: 3.13e-05 | Train Loss: 1.2725% | Train Acc: 67.75% | Val Loss: 1.3231% | Val Acc: 63.06% | Val Acc (Test Head Only): 76.38%
Epoch 69 | LR: 3.13e-05 | Train Loss: 1.2740% | Train Acc: 67.94% | Val Loss: 1.3241% | Val Acc: 63.12% | Val Acc (Test Head Only): 76.52%
Epoch 70 | LR: 3.13e-05 | Train Loss: 1.2620% | Train Acc: 67.75% | Val Loss: 1.3039% | Val Acc: 63.54% | Val Acc (Test Head Only): 76.79%
Epoch 71 | LR: 1.56e-05 | Train Loss: 1.2565% | Train Acc: 67.72% | Val Loss: 1.3155% | Val Acc: 63.29% | Val Acc (Test Head Only): 76.60%
Epoch 72 | LR: 1.56e-05 | Train Loss: 1.2546% | Train Acc: 68.30% | Val Loss: 1.3183% | Val Acc: 63.22% | Val Acc (Test Head Only): 76.56%
Epoch 73 | LR: 1.56e-05 | Train Loss: 1.2507% | Train Acc: 67.91% | Val Loss: 1.2982% | Val Acc: 63.72% | Val Acc (Test Head Only): 77.01%
→ Early stopping triggered after 6 epochs without improvement.
[Seed 46] Test Accuracy on Target Sign Subset (fc_test, test subset): 76.3382%
[Seed 46] Best Val Test Head Acc: 76.8210
[OK] Wrote sparse confusion parquet → logs_0.001_reg_64_batch_size_0.0005_lr_init_he_masked_final_v1/size_20000/test_200/train_500/seed_46/cm_size20000_train500_test200_seed46_fc-train.parquet with 7073 rows
[OK] Wrote sparse confusion parquet → logs_0.001_reg_64_batch_size_0.0005_lr_init_he_masked_final_v1/size_20000/test_200/train_500/seed_46/cm_size20000_train500_test200_seed46_fc-test-subset.parquet with 770 rows
[Seed 46] Test Accuracy on all Signs Trained (fc_train, all test): 63.1197%
[Seed 46] Best Val Train Head Acc: 63.5884
[Seed 46] Best Train Accuracy: 67.5650


=== Training Summary ===
train_acc: [0.185, 0.165, 0.21, 0.2, 0.165, 0.21, 0.285, 0.645, 1.465, 2.33, 4.47, 6.985, 9.565, 11.945, 15.02, 17.775, 20.425, 23.22, 24.75, 27.52, 28.6, 31.075, 32.545, 34.32, 35.685, 37.785, 38.605, 40.885, 41.44, 42.025, 42.92, 44.55, 45.855, 44.795, 47.175, 47.98, 48.51, 48.795, 49.125, 50.155, 50.7, 50.96, 51.965, 52.22, 52.39, 53.165, 57.85, 58.785, 59.28, 59.465, 59.61, 60.36, 60.15, 60.465, 61.295, 63.295, 64.27, 64.13, 64.425, 64.89, 64.565, 64.615, 66.1, 66.62, 66.9, 67.0, 66.415, 67.565, 67.75, 67.94, 67.745, 67.715, 68.295, 67.91]

val_acc: [0.12829512720582895, 0.11861247609595507, 0.13071578998329741, 0.11861247609595507, 0.2251216383045678, 0.32678947495824356, 0.3074241727384958, 1.5540655031347583, 2.3117329524823895, 3.9505216528285443, 7.131272542422115, 10.672702185858489, 13.989010190990292, 16.947060105056764, 20.67488078235821, 21.979618019413717, 23.623248045314806, 25.70501803393769, 28.220086659727432, 31.51945002541696, 33.586696037375035, 33.05415022633197, 36.03156544261819, 38.63135726561933, 37.99230229236765, 40.667134661470314, 43.82609958606667, 42.86993778896662, 45.59802473917359, 45.32206918254218, 43.44121420444918, 46.788990825688074, 50.156132749146714, 49.99152768027886, 49.040207208733754, 49.51465711311757, 50.7177265135194, 50.812132361840675, 47.34332260172835, 52.552588898840504, 53.54990196315751, 54.58836629469149, 51.60610975285033, 52.48481034107139, 54.37776863305173, 54.44070586526591, 57.340659872673136, 57.31887390767592, 58.5413086102975, 57.41570041877466, 59.3933819079664, 58.65992108639345, 59.008496526348914, 59.115005688557524, 59.185204909104115, 60.34470237951151, 61.494517198809035, 61.90602987097867, 61.494517198809035, 61.860037278206775, 61.274236886059406, 61.94718113819564, 62.79199244753213, 62.02948367262957, 62.71695190143061, 63.02921739972405, 62.65159400643896, 63.58839050131926, 63.06068601583114, 63.121202585267845, 63.53755658299242, 63.28822831691317, 63.218029096366585, 63.723947616857494]

val_testhead_acc: [0.7132000467672162, 0.45013445574652167, 0.4735180638372501, 0.3098328072021513, 0.3098328072021513, 0.7307377528352624, 1.0288787559920496, 3.3964690751783, 5.787443002455279, 7.839354612416696, 12.977902490354262, 17.87676838536186, 23.038699871390154, 27.610195253127557, 32.094002104524726, 33.497018589968434, 36.08090728399392, 38.401730386998715, 41.05576990529639, 44.97837016251608, 47.01858996843213, 46.72629486729802, 49.292645855255465, 52.88787559920496, 52.151291944347015, 54.55395767566936, 57.76335788612183, 56.55325616742663, 60.36478428621536, 59.762656377879104, 57.93288904477961, 61.4638138664796, 63.24096808137496, 64.38676487782065, 63.39880743598737, 63.58003039869052, 64.94797147199813, 64.17046650298141, 62.07763357886122, 66.63743715655326, 67.32725359522975, 68.96995206360342, 65.56179118437974, 66.26914532912429, 68.06968315211037, 69.15117502630656, 71.1621653221092, 71.80521454460423, 72.5008768853034, 71.6532210920145, 72.9568572430726, 72.49503098328071, 73.10300479363966, 73.0270080673448, 73.05039167543552, 74.41248684672045, 75.20168361978253, 75.37121477844032, 75.31860166023617, 75.34783117034958, 75.06138197123816, 75.15491640360108, 76.18379515959313, 75.64597217350637, 75.94411317666317, 76.54039518297674, 76.07272302116216, 76.82099848006547, 76.38255582836432, 76.517011574886, 76.78592306792937, 76.60470010522624, 76.55793288904478, 77.0080673447913]

val_loss: [6.862385841072845, 6.760794784955154, 6.605647368529319, 6.575003905036732, 6.466579157208822, 6.355471019302098, 6.136017561634105, 5.562803102911452, 5.207505784844213, 4.996765767615252, 4.515683956399716, 4.2326621448536885, 3.9680182931383423, 3.726555999237042, 3.4527748711462194, 3.3689658376104084, 3.2345413629740505, 3.15868687630854, 3.0099158729592377, 2.8270787629411473, 2.710254490123024, 2.7417475215138234, 2.580783268940832, 2.4381612661268015, 2.484686093370667, 2.337400428125309, 2.217008788377145, 2.2451017050842252, 2.0728714073819043, 2.1044447743229835, 2.2007066105587754, 2.055704388153648, 1.894373867983323, 1.9002631584349254, 1.950513735858303, 1.9312072917095806, 1.8445161079772316, 1.8665341264250284, 2.045603838082576, 1.7659200214415673, 1.7282514245718272, 1.6934370501496019, 1.8278512767663764, 1.8083072566093839, 1.7036065325688867, 1.6813344071597096, 1.5581307473235428, 1.5655755567405223, 1.5246497179231382, 1.555605822042807, 1.4681373759323249, 1.507405136354187, 1.4875211624251838, 1.4895192857794113, 1.4953400447897216, 1.4445348004047505, 1.3923815581560257, 1.3775986524591004, 1.3848082612927526, 1.390598182994375, 1.3978493492494397, 1.3813089482627465, 1.3385826515847281, 1.366203397540571, 1.3475308701933801, 1.3279045235111961, 1.3462289570896389, 1.3072976809130183, 1.3231457868423087, 1.3241034632100106, 1.3039228512782515, 1.3155042600280817, 1.3182674809936483, 1.2982411190464513]

train_loss: [6.42165576171875, 6.2936705078125, 6.2661201171875, 6.2489107421875, 6.24389296875, 6.2321451171875, 6.1575443359375, 5.96856181640625, 5.5788357421875, 5.2963638671875, 4.968090234375, 4.64786552734375, 4.3970685546875, 4.165116772460937, 3.9369407653808595, 3.7341131591796874, 3.564831246948242, 3.3918688446044922, 3.2991679565429686, 3.1522857421875, 3.072357702636719, 2.955574378967285, 2.868555305480957, 2.7646439071655275, 2.6936282524108885, 2.6158958778381347, 2.5335158752441407, 2.454086550140381, 2.4230984535217286, 2.3656287712097166, 2.32503426361084, 2.2749670135498046, 2.2032413295745847, 2.202627173614502, 2.1281040042877195, 2.084774774551392, 2.0513599235534667, 2.042923165512085, 2.0198257354736326, 1.9774487133026124, 1.9458344818115234, 1.9387161403656006, 1.9019063247680663, 1.8874648612976075, 1.8594466762542725, 1.8435015274047852, 1.6539713657379151, 1.6150915504455567, 1.5926526580810547, 1.5815259433746338, 1.5797467025756835, 1.5532063598632813, 1.5560515048980712, 1.5332835803985596, 1.510022304916382, 1.435056173324585, 1.410714920425415, 1.3901684799194336, 1.3915180465698243, 1.3658932359695435, 1.386400604057312, 1.375095574951172, 1.3268139585494996, 1.3120232833862304, 1.2983549089431763, 1.2966878580093384, 1.306620308113098, 1.2802350786209107, 1.2725198812484741, 1.2740376384735108, 1.2619676609039308, 1.2564676244735717, 1.2546403646469115, 1.2507075452804566]

val_testhead_loss: [6.097882655716968, 6.148042329107825, 6.078067905259219, 5.8983981052672085, 5.840318388093163, 5.656176131245241, 5.278458179207165, 4.647509981955086, 4.243963425178689, 4.0636364320251905, 3.5947863684472154, 3.32637592389488, 3.053089595490501, 2.860494948487163, 2.581644384126196, 2.5465968001673516, 2.421594021139989, 2.3661460337632723, 2.237422172150444, 2.0431858315100437, 1.9534407412324275, 2.000868971168291, 1.8713101284254172, 1.7149471680553254, 1.766338457468726, 1.646870979736747, 1.546917278637987, 1.5951577969863235, 1.4132617353926091, 1.4583219878334588, 1.542926853457543, 1.4239731501636763, 1.3172405541298557, 1.2952793472087496, 1.352906992710586, 1.3496922873745436, 1.2507019350190867, 1.2922299390234724, 1.4168270817210518, 1.1910738406035826, 1.1708499587175931, 1.1281988817872213, 1.2666152602108016, 1.2618067395379777, 1.153722754914928, 1.112160732186734, 1.0314439734014784, 1.0238229216598118, 0.9999804461450448, 1.0180045661087358, 0.962168347665849, 0.9869882140304699, 0.9628234054776963, 0.9842322724915438, 0.9836178030568258, 0.9347827896069856, 0.8971347584684565, 0.8833445873719955, 0.8868806256094788, 0.8941014371929943, 0.907223652175863, 0.8922777009173386, 0.8573118393194755, 0.8769874754937284, 0.8700791056574221, 0.8468454684323906, 0.8642680960295006, 0.8290462488452064, 0.8411743859338521, 0.8469333294132265, 0.8298594558760254, 0.841898435011365, 0.842998364234471, 0.8259075237373839]

best_val_loss: 1.3072976809130183

best_train_loss: 1.2802350786209107

best_val_testhead_loss: 0.8290462488452064

test_acc_fc_train: 63.11968792787207

test_acc_fc_test: 76.33816908454227

best_val_acc: 63.58839050131926

best_train_acc: 67.565

best_val_testhead_acc: 76.82099848006547

best_epoch: 67

=== Artifacts ===
Seed directory: seed_46
Confusion (train head) Parquet: seed_46/cm_size20000_train500_test200_seed46_fc-train.parquet
Confusion (test head) Parquet: seed_46/cm_size20000_train500_test200_seed46_fc-test-subset.parquet
